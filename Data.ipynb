{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from pyhessian import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/data/MNIST/mnist_train.csv')\n",
    "test = pd.read_csv('~/data/MNIST/mnist_test.csv')\n",
    "\n",
    "data = data[data['label'].isin([0, 1])]\n",
    "test = test[test['label'].isin([0, 1])]\n",
    "\n",
    "X = torch.tensor(data.drop('label', axis = 1).to_numpy(), device=device)/255\n",
    "X_test = torch.tensor(test.drop('label', axis = 1).to_numpy(), device=device)/255\n",
    "\n",
    "Y_temp = torch.tensor(data['label'].to_numpy(), device=device)\n",
    "Y = torch.eye(1, device=device)[Y_temp]\n",
    "\n",
    "Y_temp = torch.tensor(test['label'].to_numpy(), device=device)\n",
    "Y_test = torch.eye(1, device=device)[Y_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x176d23ad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.Generator(device=device)\n",
    "gen.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16ce44cd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[7].view(28,28).cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def permut_row(x, perm):\n",
    "    return x[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "n_tasks = 3\n",
    "tasks = []\n",
    "tasks_test = []\n",
    "\n",
    "for _ in range(n_tasks):\n",
    "        perm = np.random.permutation(X.shape[1])\n",
    "        tasks.append( torch.tensor(np.apply_along_axis(permut_row, axis = 1, arr=X.cpu(), perm=perm)).to(device) )\n",
    "        tasks_test.append(torch.tensor(np.apply_along_axis(permut_row, axis = 1, arr=X_test.cpu(), perm=perm)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x326350790>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tasks[1][4].cpu().view(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Standard MLP\"\"\"\n",
    "    def __init__(self, w, L):\n",
    "        super(MLP, self).__init__()\n",
    "        self.w = w\n",
    "        self.fc1 = nn.Linear(784, self.w, bias=False)\n",
    "        self.layers = nn.ModuleList(nn.Linear(self.w,self.w, bias=False) for _ in range(L))\n",
    "        self.fc2 = nn.Linear(self.w, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.L = L\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = x/np.sqrt(self.w*784)\n",
    "\n",
    "        return x\n",
    "    \n",
    "N = 128\n",
    "\n",
    "mlp = MLP(N, 4)\n",
    "summary(mlp, (1,784))\n",
    "mlp = mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=2/256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def top_eigen(model, loss, X, Y, prt=False):\n",
    "\n",
    "    hess_comp = hessian(model, loss, (X,Y) )\n",
    "    top_eigenvalues, top_eigenvector = hess_comp.eigenvalues()\n",
    "        \n",
    "    return top_eigenvalues[-1] , top_eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "MSE = nn.MSELoss()\n",
    "\n",
    "s, _ = top_eigen(mlp, MSE , X, Y)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def GSalign(model, eigen):\n",
    "   z = 0\n",
    "   for g,p in zip(model.parameters(), eigen[0]):\n",
    "        if g.requires_grad:\n",
    "          gd = g.grad\n",
    "          z += torch.sum(gd*p)/(torch.sqrt(torch.sum(gd*gd))*torch.sqrt(torch.sum(p*p))*len(eigen[0]))\n",
    "\n",
    "   return z.item()\n",
    "\n",
    "def little_ev(model):\n",
    "   \n",
    "   E = dict(model.named_parameters())['fc1.weight']\n",
    "   V = dict(model.named_parameters())['fc2.weight']\n",
    "\n",
    "   e = (E.T @ E)/(E.shape[0]*E.shape[1])\n",
    "   v = torch.sum((V @ V.T)/(E.shape[0]*E.shape[1]))\n",
    "\n",
    "   return e, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "lam = []\n",
    "all = []\n",
    "batch = len(X)\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i in range(len(X)//batch):\n",
    "\n",
    "            # Batch of training \n",
    "            ix = torch.randint(0, len(X), (batch,), generator=gen, device=device)\n",
    "\n",
    "            ixc = torch.randint(0, len(X), (2048,), generator=gen, device=device)\n",
    "            sharp, eigen = top_eigen(mlp, MSE, X[ixc], Y[ixc])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = mlp(X[ix])\n",
    "            loss = MSE(out, Y[ix])\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            all.append(GSalign(mlp,eigen))\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            lam.append(sharp)\n",
    "            loss_hist.append(loss.item())\n",
    "\n",
    "            print(f'(epoch: {epoch}), sample: {batch*(i+1)}, ---> train loss = {loss.item():.4f} -----> sharpness = {sharp:.3f}')\n",
    "\n",
    "            if epoch == 349:\n",
    "                  sharp, eigen = top_eigen(mlp, MSE, X[ixc], Y[ixc])\n",
    "                  task1_eigen = eigen\n",
    "                  \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "acc = []\n",
    "acc.append( torch.sum(torch.argmax(mlp(X_test), dim=1) == torch.argmax(Y_test, dim=1))/len(Y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(15,8))\n",
    "\n",
    "ax[0].plot(lam)\n",
    "ax[0].set_xlabel('epochs')\n",
    "ax[0].set_ylabel('Sharpness')\n",
    "\n",
    "ax[1].plot(loss_hist)\n",
    "ax[1].set_xlabel('epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "\n",
    "ax[2].plot(np.arccos(all)*180/np.pi, linestyle=':', marker='.')\n",
    "ax[2].set_xlabel('epochs')\n",
    "ax[2].set_ylabel('Alignment angle Grad-Sharp')\n",
    "ax[2].axhline(90, color='r', linestyle='dotted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc.append( torch.sum(torch.argmax(mlp(X_test), dim=1) == torch.argmax(Y_test, dim=1))/len(Y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "hess_comp = hessian( mlp, MSE, (X,Y) )\n",
    "top_eigenvalues, top_eigenvector = hess_comp.eigenvalues()\n",
    "\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "hess_comp = hessian(mlp, MSE, (X_perm,Y) )\n",
    "top_eigenvalues, top_eigenvector = hess_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is\", top_eigenvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "lr = 2/256\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=lr)\n",
    "\n",
    "old_loss = []\n",
    "batch = 1\n",
    "forg = []\n",
    "term1 = []\n",
    "term2 = []\n",
    "delta1 = [(mlp(X)[0]-Y[0]).item()]\n",
    "delta2 = [(mlp(X_perm)[0]-Y[0]).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forget(model,X1,Y1,X2,Y2,gam,lr, delta1, delta2):\n",
    "\n",
    "    e, v = little_ev(model)\n",
    "\n",
    "    term1 = N*784*(( X1 @ (e @ X2.T) + (X1 @ X2.T) * v) * delta2 * lr)\n",
    "\n",
    "    term2 = (X1 @ X2.T) @ model(X2) * delta2**2 * lr**2\n",
    "\n",
    "    f = (delta1 - (term1 - term2))\n",
    "\n",
    "    return f.item(), term1.item(), term2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "for Xt in tasks:\n",
    "        \n",
    "        for epoch in range():\n",
    "\n",
    "                running_loss = 0.0\n",
    "                for i in range(1000):\n",
    "\n",
    "                    # Batch of training \n",
    "                    ix = torch.randint(0, len(Xt), (batch,), generator=gen, device=device)\n",
    "\n",
    "                    #ixc = torch.randint(0, len(X), (1024,), generator=gen, device=device)\n",
    "                    #sharp, eigen = top_eigen(mlp, MSE, X[ixc], Y[ixc])\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "        \n",
    "                    out = mlp(Xt[ix])\n",
    "                    loss = MSE(out, Y[ix])\n",
    "                    loss.backward()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    all.append(GSalign(mlp,eigen))\n",
    "\n",
    "                    #f, t1, t2 = forget(mlp, X[ix], Y[ix], X_perm[ix], Y[ix], 0, lr, delta1[-1], delta2[-1] )\n",
    "                    #forg.append(f)\n",
    "                    #term1.append(t1)\n",
    "                    #term2.append(t2)\n",
    "                    #eigenvalues, eigenvectors = np.linalg.eigh(e.cpu().detach().numpy())\n",
    "                    #e_hist_max.append(eigenvalues[-1])\n",
    "                    #e_hist_min.append(eigenvalues[0])\n",
    "            \n",
    "                    optimizer.step()\n",
    "\n",
    "                    #delta1.append((mlp(X[ix])-Y[ix]).item())\n",
    "                    #delta2.append((mlp(X_perm[ix])-Y[ix]).item())\n",
    "                    lam.append(sharp)\n",
    "                    loss_hist.append(loss.item())\n",
    "                    old_loss.append( MSE( mlp(X[ix]), Y[ix]).item() )\n",
    "\n",
    "                    if i%100 == 0:\n",
    "                        print(f'(epoch: {epoch}), sample: {batch*(i+1)}, ---> train loss = {loss.item():.4f} -----> sharpness = {sharp:.3f}')\n",
    "\n",
    "        print('Finished Training')\n",
    "        acc.append( torch.sum(torch.argmax(mlp(X_test), dim=1) == torch.argmax(Y_test, dim=1))/len(Y_test) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=100):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "plt.plot(moving_average(np.array(old_loss)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(15,8))\n",
    "\n",
    "ax[0].plot(lam)\n",
    "ax[0].set_xlabel('epochs')\n",
    "ax[0].set_ylabel('Sharpness')\n",
    "ax[0].axvline(50, color='r', linestyle='dotted')\n",
    "ax[0].axhline(4, color='r', linestyle='dotted')\n",
    "\n",
    "\n",
    "ax[1].plot(loss_hist)\n",
    "ax[1].plot(np.arange(50,50+1000),old_loss, color='red')\n",
    "ax[1].plot(np.arange(50,50+1000),forg, color='orange')\n",
    "ax[1].set_xlabel('epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].axvline(50, color='r', linestyle='dotted')\n",
    "\n",
    "ax[2].plot(np.arccos(all)*180/np.pi, linestyle=':', marker='.')\n",
    "ax[2].set_xlabel('epochs')\n",
    "ax[2].set_ylabel('Alignment angle Grad-Sharp')\n",
    "ax[2].axvline(50, color='r', linestyle='dotted')\n",
    "ax[2].axhline(90, color='r', linestyle='dotted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(forg[0:15], label='forg', linestyle='dashed')\n",
    "plt.plot(delta1[1:16], label='delta1', alpha= 0.6)\n",
    "plt.plot(term1[0:15], label='term1', alpha= 0.6)\n",
    "plt.plot(term2[0:15], label='term2', alpha= 0.6)\n",
    "\n",
    "#plt.plot(term1[:120], label='term1' )\n",
    "#plt.plot(term2[:120], label='term2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delta1[:5])\n",
    "print(term1[:5])\n",
    "print(term2[:5])\n",
    "print(forg[:5])\n",
    "print(old_loss[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(delta1).cpu())\n",
    "plt.plot(torch.tensor(delta2).cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_term = torch.tensor((term1)/(np.array(term2)+1E-10))\n",
    "counts, bins = torch.histogram(ratio_term, range=(-10000,10000))\n",
    "plt.stairs(counts, bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(term1,term2,c = range(len(term1)), marker='+')\n",
    "clb = plt.colorbar()\n",
    "clb.ax.set_title('GD time step index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_values = [(index, value) for index, value in enumerate(term1) if value < 0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(term1)), term1, label='term1')\n",
    "plt.scatter([index for index, _ in negative_values], [value for _, value in negative_values], color='red', label='Negative Terms', marker='+')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_values = [(index, value) for index, value in enumerate(term2) if value < 0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(term2)), term2, label='term2')\n",
    "plt.scatter([index for index, _ in negative_values], [value for _, value in negative_values], color='red', label='Negative Terms', marker='+')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(term1)-np.array(term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_values = [(index, value) for index, value in enumerate(diff) if value < 0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(diff)), diff, label='term2')\n",
    "plt.scatter([index for index, _ in negative_values], [value for _, value in negative_values], color='red', label='Negative Terms', marker='+')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e_hist_max)\n",
    "plt.show()\n",
    "plt.plot(e_hist_min, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "torch.sum(torch.argmax(mlp(X_test_perm), dim=1) == torch.argmax(Y_test, dim=1))/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = torch.histogram(torch.tensor(all[:350]), 50)\n",
    "counts1, bins1 = torch.histogram(torch.tensor(all[350:]), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stairs(counts, bins)\n",
    "plt.show()\n",
    "plt.stairs(counts1, bins1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
